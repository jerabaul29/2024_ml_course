{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23392d3e-b9ab-43db-88a0-19d1da77acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56a97c-4b50-4cd1-b854-4b844c6f9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./training_data_pandas.pkl\", \"br\") as fh:\n",
    "    data = pkl.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6792a5-3391-4757-a6fb-4e197a39a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: some data exloration\n",
    "\n",
    "# what kind object is \"data\"?\n",
    "# what columns are there?\n",
    "# what is the list of unique station names?\n",
    "\n",
    "# rsds_stations is the in-situ observations in W/m**2\n",
    "# integral_of_surface_downwelling_shortwave_flux_in_air_wrt_time_nora3 is the nora3 estimate\n",
    "# and surface_solar_radiation_downwards_era5 the era5 one\n",
    "# these are in Wh/m**2 (accumulated hourly values); create rsds_era5 and rsds_nora3 columns in data with the same normalization as rsds_stations\n",
    "\n",
    "# plot rsds_stations for 1 station; what can you observe?\n",
    "# what is the distribution of data in the rsds_stations column for the station? Is this a well balanced dataset? What could you do to make it \"better balanced\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378aa143-d8b1-49d0-ad9f-f4b89185b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a77c46-7609-4d35-84aa-1a5ca3fe2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff99966-a4ef-4991-8dc0-b5ebe98826de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e03108-9ab2-4d41-84c5-251f70f65afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rsds_nora3\"] = data[\"integral_of_surface_downwelling_shortwave_flux_in_air_wrt_time_nora3\"] / 3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456de6fc-aa0d-423f-80d3-bb930379fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rsds_era5\"] = data[\"surface_solar_radiation_downwards_era5\"] / 3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93692bc-b328-4910-b958-922afb214ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d943b6-f594-4b5b-9242-229afb5e03da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib tk\n",
    "\n",
    "crrt_data = data[data[\"name\"] == \"OSLO - BLINDERN\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(crrt_data[\"time_stations\"], crrt_data[\"rsds_stations\"])\n",
    "plt.ylabel(\"W/m**2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0dd596-1c27-43cb-bec6-be1026cf92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib tk\n",
    "\n",
    "crrt_data = data[data[\"name\"] == \"TRONDHEIM - GLØSHAUGEN\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(crrt_data[\"time_stations\"], crrt_data[\"rsds_stations\"])\n",
    "plt.ylabel(\"W/m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8886a-9f78-44c2-aa99-cbc309820776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "crrt_data = data[data[\"name\"] == \"TRONDHEIM - GLØSHAUGEN\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(crrt_data[\"rsds_stations\"], bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95743762-32ce-4238-8155-b0a5701022f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61b605-e317-4634-875f-27dc6b960436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: prepare the data\n",
    "\n",
    "# Keep only the data where:\n",
    "# “full_valid_flag” is True\n",
    "# rsds_stations > 50.0\n",
    "# rsds_nora3 > 50.0\n",
    "\n",
    "# split between the training and validation datasets; use as a validation dataset the specific stations:\n",
    "# \"DOVRE-LANNEM\",\n",
    "# \"TJØLLING\",\n",
    "# \"GRAN\",\n",
    "# \"RAKKESTAD\",\n",
    "# \"ÅS\",\n",
    "# make *really* sure that the stations are well separated between the two, this is really important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582041c-2e65-41c8-a0b0-d29dd1d53441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0f8f7-391f-4931-bd65-5a26d0a5d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indexes = np.logical_and.reduce(\n",
    "    (\n",
    "        data[\"full_valid_flag\"] == True,\n",
    "        data[\"rsds_stations\"] > 50.0,  # only use the cases when there is actually sun energy (not night)\n",
    "        data[\"rsds_nora3\"] > 50.0,  # only use the cases when there is actually sun energy (not night)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b1808-10e7-43e0-901b-de716a2fa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = data.loc[valid_indexes].reset_index()\n",
    "print(f\"size of valid_pd_all_data: {len(valid_data):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa876ea9-a320-4ce2-aaab-5512eee0f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stations_for_validation = [\n",
    "    \"DOVRE-LANNEM\",\n",
    "    \"TJØLLING\",\n",
    "    \"GRAN\",\n",
    "    \"RAKKESTAD\",\n",
    "    \"ÅS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c017b3c-88c7-47a4-857f-c69ef63d43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name_match_validation = [valid_data[\"name\"] == st for st in list_stations_for_validation]\n",
    "tuple_name_match_validation = tuple(list_name_match_validation)\n",
    "\n",
    "# list our conditions to be a validation station\n",
    "valid_indexes_validation = np.logical_or.reduce(\n",
    "    tuple_name_match_validation\n",
    ")\n",
    "\n",
    "data_validation = valid_data.loc[valid_indexes_validation].reset_index().squeeze()\n",
    "data_training = valid_data.loc[np.logical_not(valid_indexes_validation)].reset_index().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc76a2-6610-41f7-8c67-ee12ea12926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(data_validation) = }\")\n",
    "print(f\"{len(data_training) = }\")\n",
    "print(f\"{len(data_validation) + len(data_training) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e5a51-45f9-4a46-b0ec-5288f6af2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65a021-7892-4b11-a979-5cd74a8e477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abc40e-7ae3-4e5e-80d7-cbe0686354d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cdbf2-1b66-404b-9325-7cc13e3a7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK\n",
    "\n",
    "# print the MAE, RMSE, relative variance level, between the rsds_nora3, rsds_era5, SSI_value_cmsaf_sis\n",
    "# and the rsds_stations\n",
    "\n",
    "# do this for both the full dataset, and for the training and validation datasets individually\n",
    "\n",
    "# plot and interpret the data in a Taylor plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd8d6-0da9-448c-ba52-9b67552a2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data_in, estimate_name):\n",
    "    rsds = data_in[\"rsds_stations\"].to_numpy()\n",
    "    estimate = data_in[estimate_name].to_numpy()\n",
    "    \n",
    "    mae = np.mean(np.abs(rsds-estimate))\n",
    "    rmse = np.sqrt(np.mean((rsds-estimate)**2))\n",
    "    variance_ratio = np.std(estimate) / np.std(rsds)\n",
    "\n",
    "    print(f\"{estimate_name = }\")\n",
    "    print(f\"{mae = }\")\n",
    "    print(f\"{rmse = }\")\n",
    "    print(f\"{variance_ratio = }\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826ebe7-28e9-4cf0-91d5-2ace7609d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = valid_data\n",
    "\n",
    "print(\"all valid data\")\n",
    "print(\"\")\n",
    "\n",
    "print_stats(data_stats, \"rsds_nora3\")\n",
    "print_stats(data_stats, \"rsds_era5\")\n",
    "print_stats(data_stats, \"SSI_value_cmsaf_sis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc61d20-d204-4605-a783-26bd94c8cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = data_training\n",
    "\n",
    "print(\"data_training\")\n",
    "print(\"\")\n",
    "\n",
    "print_stats(data_stats, \"rsds_nora3\")\n",
    "print_stats(data_stats, \"rsds_era5\")\n",
    "print_stats(data_stats, \"SSI_value_cmsaf_sis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac127d-f7bf-430d-b100-32762ec5caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats = data_validation\n",
    "\n",
    "print(\"data_validation\")\n",
    "print(\"\")\n",
    "\n",
    "print_stats(data_stats, \"rsds_nora3\")\n",
    "print_stats(data_stats, \"rsds_era5\")\n",
    "print_stats(data_stats, \"SSI_value_cmsaf_sis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7828c74-19bf-4f8a-bdff-b47e57740180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skill_metrics as sm\n",
    "from skill_metrics.check_taylor_stats import check_taylor_stats\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0e3e4-8c9f-4ba2-8272-1d3411a30962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taylor_plot_stats(data_in, field_label_name, field_model_name):\n",
    "    field_label_np = data_in.loc[:, field_label_name].to_numpy().astype(np.float32)\n",
    "    field_model_np = data_in.loc[:, field_model_name].to_numpy().astype(np.float32)\n",
    "    \n",
    "    sdev_ref_label = np.std(field_label_np)\n",
    "    field_label_np_normalized = field_label_np / sdev_ref_label\n",
    "    field_model_np_normalized = field_model_np / sdev_ref_label\n",
    "\n",
    "    sdev = np.std(field_model_np_normalized)\n",
    "    crmsd = sm.centered_rms_dev(field_label_np_normalized, field_model_np_normalized)\n",
    "    ccoef = np.corrcoef(field_label_np_normalized, field_model_np_normalized)[0,1]\n",
    "    \n",
    "    return (sdev, crmsd, ccoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867d138-a801-4dba-8659-d1a7ed9135da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=17)\n",
    "\n",
    "plt.figure(num=1, figsize=(16, 12))\n",
    "\n",
    "first_Taylor_diagram = True\n",
    "\n",
    "list_colors = [\"r\", \"k\", \"y\", \"b\", \"g\", \"m\", \"c\", \"darkorange\", \"lime\", \"paleturquoise\", \"gold\"]\n",
    "dict_label = {\"observations\": \"c\"}\n",
    "\n",
    "data_to_use = data_validation\n",
    "\n",
    "init_sdev, init_crmsd, init_ccoef = get_taylor_plot_stats(data_to_use, \"rsds_stations\", \"rsds_stations\")\n",
    "\n",
    "list_columns_model = [\n",
    "    \"rsds_nora3\",\n",
    "    \"rsds_era5\",\n",
    "    \"SSI_value_cmsaf_sis\",\n",
    "]\n",
    "\n",
    "for crrt_color, crrt_model in zip(list_colors[0:len(list_columns_model)], list_columns_model):\n",
    "    dict_label[crrt_model] = crrt_color\n",
    "    \n",
    "    crrt_list_sdev = [init_sdev]\n",
    "    crrt_list_crmsd = [init_crmsd]\n",
    "    crrt_list_ccoef = [init_ccoef]\n",
    "    \n",
    "    list_stations_to_use = data_to_use.name.unique()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        \n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "\n",
    "        crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_crrt_station, \"rsds_stations\", crrt_model)\n",
    "        crrt_list_sdev.append(crrt_sdev)\n",
    "        crrt_list_crmsd.append(crrt_crmsd)\n",
    "        crrt_list_ccoef.append(crrt_ccoef)\n",
    "        \n",
    "    crrt_sdev = np.array(crrt_list_sdev)\n",
    "    crrt_crmsd = np.array(crrt_list_crmsd)\n",
    "    crrt_ccoef = np.array(crrt_list_ccoef)\n",
    "    \n",
    "    if first_Taylor_diagram:\n",
    "        sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, markercolor=crrt_color, markersize=4)\n",
    "    else:\n",
    "        sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, overlay = 'on', markercolor=crrt_color, markerLabel=dict_label, markersize=5)\n",
    "    \n",
    "    first_Taylor_diagram = False\n",
    "    \n",
    "    pd_to_aggregate = pd.DataFrame()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "        if len(pd_crrt_station) < 20:\n",
    "            continue\n",
    "        pd_to_aggregate = pd.concat([pd_to_aggregate, pd_crrt_station], ignore_index=True)\n",
    "    \n",
    "    # inspired from https://github.com/PeterRochford/SkillMetrics/blob/master/skill_metrics/taylor_diagram.py to put in the correct polar coordinates\n",
    "    crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_to_aggregate, \"rsds_stations\", crrt_model)\n",
    "    crrt_sdev = np.array([crrt_sdev])\n",
    "    crrt_crmsd = np.array([crrt_crmsd])\n",
    "    crrt_ccoef = np.array([crrt_ccoef])\n",
    "    check_taylor_stats(crrt_sdev, crrt_crmsd, crrt_ccoef, 0.01)\n",
    "    rho, theta = crrt_sdev, np.arccos(crrt_ccoef)\n",
    "    \n",
    "    plt.scatter(rho * np.cos(theta), rho * np.sin(theta), s=[512], c=[crrt_color], marker=\"X\", label=crrt_model)\n",
    "    \n",
    "plt.scatter([1.0], [0.0], s=[512], c=[\"c\"], label=\"truth\")\n",
    "plt.legend(bbox_to_anchor=(1.25, 1.25), loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fc9e6-85af-4ce5-8dda-b57d07cff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=17)\n",
    "\n",
    "plt.figure(num=1, figsize=(16, 12))\n",
    "\n",
    "first_Taylor_diagram = True\n",
    "\n",
    "list_colors = [\"r\", \"k\", \"y\", \"b\", \"g\", \"m\", \"c\", \"darkorange\", \"lime\", \"paleturquoise\", \"gold\"]\n",
    "dict_label = {\"observations\": \"c\"}\n",
    "\n",
    "data_to_use = data_training\n",
    "\n",
    "init_sdev, init_crmsd, init_ccoef = get_taylor_plot_stats(data_to_use, \"rsds_stations\", \"rsds_stations\")\n",
    "\n",
    "list_columns_model = [\n",
    "    \"rsds_nora3\",\n",
    "    \"rsds_era5\",\n",
    "    \"SSI_value_cmsaf_sis\",\n",
    "]\n",
    "\n",
    "for crrt_color, crrt_model in zip(list_colors[0:len(list_columns_model)], list_columns_model):\n",
    "    dict_label[crrt_model] = crrt_color\n",
    "    \n",
    "    crrt_list_sdev = [init_sdev]\n",
    "    crrt_list_crmsd = [init_crmsd]\n",
    "    crrt_list_ccoef = [init_ccoef]\n",
    "    \n",
    "    list_stations_to_use = data_to_use.name.unique()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        \n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "\n",
    "        crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_crrt_station, \"rsds_stations\", crrt_model)\n",
    "        crrt_list_sdev.append(crrt_sdev)\n",
    "        crrt_list_crmsd.append(crrt_crmsd)\n",
    "        crrt_list_ccoef.append(crrt_ccoef)\n",
    "        \n",
    "    crrt_sdev = np.array(crrt_list_sdev)\n",
    "    crrt_crmsd = np.array(crrt_list_crmsd)\n",
    "    crrt_ccoef = np.array(crrt_list_ccoef)\n",
    "    \n",
    "    if first_Taylor_diagram:\n",
    "        sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, markercolor=crrt_color, markersize=4)\n",
    "    else:\n",
    "        sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, overlay = 'on', markercolor=crrt_color, markerLabel=dict_label, markersize=5)\n",
    "    \n",
    "    first_Taylor_diagram = False\n",
    "    \n",
    "    pd_to_aggregate = pd.DataFrame()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "        if len(pd_crrt_station) < 20:\n",
    "            continue\n",
    "        pd_to_aggregate = pd.concat([pd_to_aggregate, pd_crrt_station], ignore_index=True)\n",
    "    \n",
    "    # inspired from https://github.com/PeterRochford/SkillMetrics/blob/master/skill_metrics/taylor_diagram.py to put in the correct polar coordinates\n",
    "    crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_to_aggregate, \"rsds_stations\", crrt_model)\n",
    "    crrt_sdev = np.array([crrt_sdev])\n",
    "    crrt_crmsd = np.array([crrt_crmsd])\n",
    "    crrt_ccoef = np.array([crrt_ccoef])\n",
    "    check_taylor_stats(crrt_sdev, crrt_crmsd, crrt_ccoef, 0.01)\n",
    "    rho, theta = crrt_sdev, np.arccos(crrt_ccoef)\n",
    "    \n",
    "    plt.scatter(rho * np.cos(theta), rho * np.sin(theta), s=[512], c=[crrt_color], marker=\"X\", label=crrt_model)\n",
    "    \n",
    "plt.scatter([1.0], [0.0], s=[512], c=[\"c\"], label=\"truth\")\n",
    "plt.legend(bbox_to_anchor=(1.25, 1.25), loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f733c3-e457-49c6-bc8e-5d8b69519a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ccfa0-6988-4ec9-8ef0-ac736e52b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Apply a simple linear regression model\n",
    "\n",
    "# The simplest model one can think about is a linear regression model\n",
    "# Apply a linear regression model to the problem; choose the predictors that make sense\n",
    "# How do the results look like? How does this relate to the “BLUE” estimator theory?\n",
    "# “Why” does this work?\n",
    "# Can you estimate how much importance is given to each predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f21ed-df25-4767-ba8a-8263a36477fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0710143-8ec9-4376-9f96-e43ad5c166ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"rsds_stations\"\n",
    "\n",
    "list_predictors_to_use = [\n",
    "    'integral_of_surface_net_downward_shortwave_flux_wrt_time_nora3',\n",
    "    'integral_of_toa_net_downward_shortwave_flux_wrt_time_nora3',\n",
    "    'air_temperature_2m_nora3',\n",
    "    'low_type_cloud_area_fraction_nora3',\n",
    "    'cloud_area_fraction_nora3',\n",
    "    'lwe_thickness_of_atmosphere_mass_content_of_water_vapor_nora3',\n",
    "    'convective_cloud_area_fraction_nora3',\n",
    "    'medium_type_cloud_area_fraction_nora3',\n",
    "    'high_type_cloud_area_fraction_nora3',\n",
    "    'precipitation_amount_acc_nora3',\n",
    "    'rsds_nora3',\n",
    "    'rsds_era5',\n",
    "    'snowfall_amount_acc_nora3',\n",
    "    'ASN_VEG_nora3',\n",
    "    'TALB_ISBA_nora3',\n",
    "    'LAI_nora3',\n",
    "    'VEG_nora3',\n",
    "    'top_net_solar_radiation_era5',\n",
    "    'surface_net_solar_radiation_era5',\n",
    "    'surface_solar_radiation_downwards_era5',\n",
    "    'total_cloud_cover_era5',\n",
    "    'high_cloud_cover_era5',\n",
    "    'medium_cloud_cover_era5',\n",
    "    'low_cloud_cover_era5',\n",
    "    'snowfall_era5',\n",
    "    'total_precipitation_era5',\n",
    "    'snow_albedo_era5',\n",
    "    'forecast_albedo_era5',\n",
    "    'leaf_area_index_low_vegetation_era5',\n",
    "    'leaf_area_index_high_vegetation_era5',\n",
    "    'total_column_water_vapour_era5',\n",
    "    'SSI_value_cmsaf_sis_sarah',\n",
    "    'SSI_value_cmsaf_sis_sarah_minus_30mins',\n",
    "    'SSI_value_cmsaf_sis_sarah_plus_30mins',\n",
    "]\n",
    "\n",
    "for crrt_predictor in list_predictors_to_use:\n",
    "    if crrt_predictor not in data:\n",
    "        raise RuntimeError(f\"predictor {crrt_predictor} is required but not found in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f70fc-cc43-49cd-aa94-67928a9f5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# extract: labels and predictors extraction\n",
    "\n",
    "np_predictors_training = data_training.loc[:, list_predictors_to_use].to_numpy(dtype=np.float32)\n",
    "np_labels_training = data_training.loc[:, label_column].to_numpy(dtype=np.float32).squeeze()\n",
    "np_rsds_stations_training = data_training.loc[:, \"rsds_stations\"].to_numpy(dtype=np.float32).squeeze()\n",
    "\n",
    "np_predictors_validation = data_validation.loc[:, list_predictors_to_use].to_numpy(dtype=np.float32)\n",
    "np_labels_validation = data_validation.loc[:, label_column].to_numpy(dtype=np.float32).squeeze()\n",
    "np_rsds_stations_validation = data_validation.loc[:, \"rsds_stations\"].to_numpy(dtype=np.float32).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03ae8d-4980-4ea5-b364-651cd1de9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the linear fitting and prediction\n",
    "\n",
    "X_train = np_predictors_training\n",
    "y_train = np_labels_training\n",
    "X_test = np_predictors_validation\n",
    "y_test = np_labels_validation\n",
    "\n",
    "# Create the linear regression object\n",
    "# \"vanilla\" linear regression\n",
    "model_kind = \"LR\"\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable using the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba28a7b-3fad-4c1c-b704-0568265acb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the predictions\n",
    "linear_predicted_training = np.array(model.predict(X_train)).squeeze()\n",
    "linear_predicted_validation = np.array(model.predict(X_test)).squeeze()\n",
    "\n",
    "data_training[\"rsds_sklearn\"] = linear_predicted_training\n",
    "data_validation[\"rsds_sklearn\"] = linear_predicted_validation\n",
    "\n",
    "# show statistics\n",
    "print(\"sklearn linear regression\")\n",
    "\n",
    "# on training data\n",
    "print(\"--- training ---\")\n",
    "print(\"linear model\")\n",
    "print(f\"{np.mean(np.abs((linear_predicted_training-np_rsds_stations_training))) = }\")\n",
    "print(f\"{np.sqrt(np.mean((linear_predicted_training-np_rsds_stations_training)**2)) = }\")\n",
    "\n",
    "# on validation data\n",
    "print(\"--- validation ---\")\n",
    "print(\"linear model\")\n",
    "print(f\"{np.mean(np.abs((linear_predicted_validation-np_rsds_stations_validation))) = }\")\n",
    "print(f\"{np.sqrt(np.mean((linear_predicted_validation-np_rsds_stations_validation)**2)) = }\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd60a7-2ad8-4032-8f3f-5aa555066a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_predictors_to_use_plot = list_predictors_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7107dc-a6df-4767-bb61-d03f86d9d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cde8ee-7f4a-4c4b-95e8-b2ad12014148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at coeff * std, to see the importance of each coeff in the model (not this is only \"marginal\" importance when keeping everything else the same\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model.coef_ * X_train.std(axis=0) / y_train.std(axis=0),\n",
    "    columns=[\"Coefficient importance\"],\n",
    "    index=list_predictors_to_use,\n",
    ")\n",
    "\n",
    "coefs_to_plot = coefs[coefs.index.isin(list_predictors_to_use_plot)]\n",
    "print(f\"{len(coefs_to_plot)}\")\n",
    "\n",
    "coefs_to_plot.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.xlabel(\"Coefficient values corrected by the feature's std. dev.\")\n",
    "plt.title(\"\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)\n",
    "plt.title(\"Sklean linear model\")\n",
    "\n",
    "import seaborn as sns\n",
    "# Declaring the cm variable by the\n",
    "# color palette from seaborn\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "\n",
    "coefs.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b07616-0b2f-435a-ba1e-6ae995e68e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7438c-9c48-4af7-b62a-6bd8890c3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: training a simple model\n",
    "\n",
    "# What kind of NN model would make sense in the present situation\n",
    "\n",
    "# Define and train the NN model in Keras\n",
    "# How do the results compare with the other methods?\n",
    "# Put it all in a common Taylor plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c65b6-0647-485d-9b28-61bcf2684c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37546353-f33e-4f25-8f91-dc392aabaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"perform normalization adaptation\")\n",
    "\n",
    "labels_inv_normalization_layer = layers.Normalization(invert=True, input_shape=[1,], axis=None)\n",
    "labels_inv_normalization_layer.adapt(np_labels_training)\n",
    "\n",
    "predictors_normalization_layer = layers.Normalization()\n",
    "predictors_normalization_layer.adapt(np_predictors_training)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04c15e-0c7b-4a5c-aabe-e39c70aa4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML setup\n",
    "\n",
    "# define a simple NN\n",
    "\n",
    "input_layer = keras.layers.Input(shape=(np_predictors_training.shape[1], ))\n",
    "normalized_input = predictors_normalization_layer(input_layer)\n",
    "\n",
    "fully_connected_1 = keras.layers.Dense(40, activation=\"relu\")(normalized_input)\n",
    "fully_connected_2 = keras.layers.Dense(40, activation=\"relu\")(fully_connected_1)\n",
    "fully_connected_3 = keras.layers.Dense(40, activation=\"relu\")(fully_connected_2)\n",
    "fully_connected_4 = keras.layers.Dense(40, activation=\"relu\")(fully_connected_3)\n",
    "\n",
    "output = keras.layers.Dense(1)(fully_connected_4)\n",
    "denormalized_output = labels_inv_normalization_layer(output)\n",
    "\n",
    "# metaparameters\n",
    "learning_rate = 5e-4\n",
    "loss_kind = \"mean_absolute_error\"\n",
    "\n",
    "# model\n",
    "keras_model = keras.Model(inputs=input_layer, outputs=denormalized_output)\n",
    "keras_model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=learning_rate), loss=loss_kind)\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242f67b-f11a-4272-8793-0e110f0f86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = int(4e1)\n",
    "min_delta_stop = 1e-7\n",
    "patience_stop = 10\n",
    "\n",
    "# training config\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=min_delta_stop, patience=patience_stop)\n",
    "\n",
    "# shuffling of the data\n",
    "permutation_indexes = np.random.permutation(np.arange(0, np_predictors_training.shape[0]))\n",
    "np_predictors_training_perm = np_predictors_training[permutation_indexes, :]\n",
    "np_labels_training_perm = np_labels_training[permutation_indexes]\n",
    "\n",
    "# reduce the size of the dataset for going faster in tests\n",
    "reduce_dataset = False\n",
    "reduction_keep_factor = 0.3  # only use 1/3 of the data\n",
    "\n",
    "if reduce_dataset:\n",
    "    print(\"W reducing the size of the dataset;\")\n",
    "    print(\"W this is only fine for testing\")\n",
    "    max_index = int(reduction_keep_factor * np_predictors_training.shape[0])\n",
    "else:\n",
    "    max_index = np_predictors_training.shape[0]\n",
    "    \n",
    "np_predictors_training_perm_red = np_predictors_training_perm[:max_index, :]\n",
    "np_labels_training_perm_red = np_labels_training_perm[:max_index]\n",
    "\n",
    "# perform learning\n",
    "history = keras_model.fit(\n",
    "    x=np_predictors_training_perm_red,\n",
    "    y=np_labels_training_perm_red,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.10,\n",
    "    # what callbacks to use... seems the checkpoint callback does not help and only slows down\n",
    "    # callbacks=[es_callback, model_ckpt_callback, scheduler_callback]\n",
    "    callbacks=[es_callback],\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21478aaa-51e5-411b-9df5-23240e0d0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epoch = list(range(len(loss)))\n",
    "\n",
    "# to avoid obscuring the learning curve with initial sharp decay\n",
    "start_epoch_idx = 10\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch[start_epoch_idx:], loss[start_epoch_idx:], \"b\", label=\"training loss\")\n",
    "plt.plot(epoch[start_epoch_idx:], val_loss[start_epoch_idx:], \"k\", label=\"validation loss\")\n",
    "plt.title(\"training curve\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b63bdb-2b71-4d7e-822c-7718b109d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the predictions\n",
    "predicted_training = np.array(keras_model(np_predictors_training)).squeeze()\n",
    "predicted_validation = np.array(keras_model(np_predictors_validation)).squeeze()\n",
    "\n",
    "# on training data\n",
    "print(\"--- training ---\")\n",
    "print(\"nn\")\n",
    "print(f\"{np.mean(np.abs((predicted_training-np_rsds_stations_training))) = }\")\n",
    "print(f\"{np.sqrt(np.mean((predicted_training-np_rsds_stations_training)**2)) = }\")\n",
    "\n",
    "# on validation data\n",
    "print(\"--- validation ---\")\n",
    "print(\"nn\")\n",
    "print(f\"{np.mean(np.abs((predicted_validation-np_rsds_stations_validation))) = }\")\n",
    "print(f\"{np.sqrt(np.mean((predicted_validation-np_rsds_stations_validation)**2)) = }\")\n",
    "\n",
    "data_training[\"rsds_fcnn\"] = predicted_training\n",
    "data_validation[\"rsds_fcnn\"] = predicted_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a342e08-8a05-4e25-ba1e-dc04fa9ba255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=17)\n",
    "\n",
    "plt.figure(num=1, figsize=(16, 12))\n",
    "\n",
    "first_Taylor_diagram = True\n",
    "\n",
    "list_colors = [\"r\", \"k\", \"y\", \"b\", \"g\", \"m\", \"c\", \"darkorange\", \"lime\", \"paleturquoise\", \"gold\"]\n",
    "dict_label = {\"observations\": \"c\"}\n",
    "\n",
    "data_to_use = data_validation\n",
    "\n",
    "init_sdev, init_crmsd, init_ccoef = get_taylor_plot_stats(data_to_use, \"rsds_stations\", \"rsds_stations\")\n",
    "\n",
    "list_columns_model = [\n",
    "    \"rsds_nora3\",\n",
    "    \"rsds_era5\",\n",
    "    \"SSI_value_cmsaf_sis\",\n",
    "    \"rsds_sklearn\",\n",
    "    \"rsds_fcnn\",\n",
    "]\n",
    "\n",
    "for crrt_color, crrt_model in zip(list_colors[0:len(list_columns_model)], list_columns_model):\n",
    "    dict_label[crrt_model] = crrt_color\n",
    "    \n",
    "    crrt_list_sdev = [init_sdev]\n",
    "    crrt_list_crmsd = [init_crmsd]\n",
    "    crrt_list_ccoef = [init_ccoef]\n",
    "    \n",
    "    list_stations_to_use = data_to_use.name.unique()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        \n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "\n",
    "        crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_crrt_station, \"rsds_stations\", crrt_model)\n",
    "        crrt_list_sdev.append(crrt_sdev)\n",
    "        crrt_list_crmsd.append(crrt_crmsd)\n",
    "        crrt_list_ccoef.append(crrt_ccoef)\n",
    "        \n",
    "    crrt_sdev = np.array(crrt_list_sdev)\n",
    "    crrt_crmsd = np.array(crrt_list_crmsd)\n",
    "    crrt_ccoef = np.array(crrt_list_ccoef)\n",
    "\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    if first_Taylor_diagram:\n",
    "        sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, markercolor=crrt_color, markersize=4)\n",
    "    else:\n",
    "        try:\n",
    "            sm.taylor_diagram(crrt_sdev, crrt_crmsd, crrt_ccoef, overlay = 'on', markercolor=crrt_color, markerLabel=dict_label, markersize=5)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    first_Taylor_diagram = False\n",
    "    \n",
    "    pd_to_aggregate = pd.DataFrame()\n",
    "    \n",
    "    for crrt_station in list_stations_to_use:\n",
    "        pd_crrt_station = data_to_use[data_to_use[\"name\"] == crrt_station]\n",
    "        if len(pd_crrt_station) < 20:\n",
    "            continue\n",
    "        pd_to_aggregate = pd.concat([pd_to_aggregate, pd_crrt_station], ignore_index=True)\n",
    "    \n",
    "    # inspired from https://github.com/PeterRochford/SkillMetrics/blob/master/skill_metrics/taylor_diagram.py to put in the correct polar coordinates\n",
    "    crrt_sdev, crrt_crmsd, crrt_ccoef = get_taylor_plot_stats(pd_to_aggregate, \"rsds_stations\", crrt_model)\n",
    "    crrt_sdev = np.array([crrt_sdev])\n",
    "    crrt_crmsd = np.array([crrt_crmsd])\n",
    "    crrt_ccoef = np.array([crrt_ccoef])\n",
    "    check_taylor_stats(crrt_sdev, crrt_crmsd, crrt_ccoef, 0.01)\n",
    "    rho, theta = crrt_sdev, np.arccos(crrt_ccoef)\n",
    "    \n",
    "    plt.scatter(rho * np.cos(theta), rho * np.sin(theta), s=[512], c=[crrt_color], marker=\"X\", label=crrt_model)\n",
    "    \n",
    "plt.scatter([1.0], [0.0], s=[512], c=[\"c\"], label=\"truth\")\n",
    "plt.legend(bbox_to_anchor=(1.25, 1.25), loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067409bf-e089-434b-b9c1-ab48f582fb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
